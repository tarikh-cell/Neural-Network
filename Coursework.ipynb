{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34-icOT_svXq"
      },
      "outputs": [],
      "source": [
        "# Setting up google drive \n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True)\n",
        "# import sys\n",
        "# sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyjJDChqs1UZ"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import my_utils as mu\n",
        "import torch\n",
        "from torch import nn\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_NUEW2Ps3Yn"
      },
      "outputs": [],
      "source": [
        "#Dataset and DataLoader\n",
        "batch_size = 256 # Pick batch size\n",
        "train_iter, test_iter = mu.load_data_fashion_mnist(batch_size) # Load Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qKJOshBvFe7v"
      },
      "outputs": [],
      "source": [
        "#Stem\n",
        "def stem(X):\n",
        "  matrixM = [] # Initialize empty array to store tensors\n",
        "  for image in X:\n",
        "    # Split array in the first dimension into 4 separate arrays\n",
        "    patch = torch.tensor_split(image, 4, dim=1)\n",
        "\n",
        "    # Reshape the tesnor so all patches are ordered correctly\n",
        "    new_patch = []\n",
        "    for x in patch:\n",
        "      new_patch.append(x.reshape(28,7))\n",
        "\n",
        "    # Split array in the next dimension and append to array\n",
        "    patches = []\n",
        "    for i in range(len(new_patch)):\n",
        "      for j in range(len(new_patch)):\n",
        "        patches.append(torch.tensor_split(new_patch[i], 4, dim=0)[j]) \n",
        "        \n",
        "    new_patches = torch.empty([0,1])\n",
        "    # add each separate array to a new tensor to create a Matrix\n",
        "    new_patches = torch.stack([p for p in patches])\n",
        "\n",
        "    # flatten tensor so that each tensor is on one line\n",
        "    new_patches = new_patches.flatten(1)\n",
        "\n",
        "    # create linear layer\n",
        "    convert_to_linear = nn.Linear(49, 49)\n",
        "    feature_vector = convert_to_linear(new_patches)\n",
        "    matrixM.append(feature_vector)\n",
        "  \n",
        "    # Create a tensor \n",
        "    M = torch.stack([p for p in matrixM])\n",
        "  return M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-9T4z5uYGrO"
      },
      "outputs": [],
      "source": [
        "#Backbone\n",
        "import torch.nn.functional as F\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super(Net, self).__init__()\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_outputs = num_outputs\n",
        "        self.Linear1 = nn.Linear(num_inputs, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear1.weight)\n",
        "        torch.nn.init.zeros_(self.Linear1.bias)\n",
        "\n",
        "        self.Linear2 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear2.weight)\n",
        "        torch.nn.init.zeros_(self.Linear2.bias)\n",
        "\n",
        "        self.Linear3 = nn.Linear(49, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear3.weight)\n",
        "        torch.nn.init.zeros_(self.Linear3.bias)\n",
        "\n",
        "        self.Linear4 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear4.weight)\n",
        "        torch.nn.init.zeros_(self.Linear4.bias)\n",
        "\n",
        "        self.Linear5 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear5.weight)\n",
        "        torch.nn.init.zeros_(self.Linear5.bias)\n",
        "\n",
        "        self.Linear6 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear6.weight)\n",
        "        torch.nn.init.zeros_(self.Linear6.bias)\n",
        "\n",
        "        self.Linear7 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear7.weight)\n",
        "        torch.nn.init.zeros_(self.Linear7.bias)\n",
        "\n",
        "        self.Linear8 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear8.weight)\n",
        "        torch.nn.init.zeros_(self.Linear8.bias)\n",
        "\n",
        "        self.Linear9 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear9.weight)\n",
        "        torch.nn.init.zeros_(self.Linear9.bias)\n",
        "\n",
        "        self.Linear10 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear10.weight)\n",
        "        torch.nn.init.zeros_(self.Linear10.bias)\n",
        "\n",
        "        self.Linear11 = nn.Linear(num_hidden, num_hidden)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear11.weight)\n",
        "        torch.nn.init.zeros_(self.Linear11.bias)\n",
        "\n",
        "        self.Linear12 = nn.Linear(num_hidden, 10)\n",
        "        torch.nn.init.kaiming_normal_(self.Linear12.weight)\n",
        "        torch.nn.init.zeros_(self.Linear12.bias)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        arr = []\n",
        "        for x in image:\n",
        "          x = torch.transpose(x, 0, 1)\n",
        "          x = self.Linear1(x)\n",
        "          x = self.relu(x)\n",
        "          x = self.Linear2(x)\n",
        "\n",
        "          x = torch.transpose(x, 0, 1)\n",
        "          x = self.Linear3(x)\n",
        "          x = self.relu(x)\n",
        "          x = self.Linear4(x)\n",
        "\n",
        "          x = torch.transpose(x, 0, 1)\n",
        "          x = self.Linear9(x)\n",
        "          x = self.relu(x)\n",
        "          x = self.Linear10(x)\n",
        "\n",
        "          x = torch.transpose(x, 0, 1)\n",
        "          x = self.Linear11(x)\n",
        "          x = self.relu(x)\n",
        "          x = self.Linear12(x)\n",
        "\n",
        "          arr.append(x)\n",
        "\n",
        "        new_arr = torch.stack(arr, dim=0)\n",
        "\n",
        "        x = torch.mean(new_arr, 1)\n",
        "        out = F.log_softmax(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "num_inputs, num_outputs = 16, 49\n",
        "num_hidden = 32\n",
        "net = Net(num_inputs, num_hidden, num_outputs)\n",
        "# Initialize net with hidden layers and params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5p1anMpzc76"
      },
      "outputs": [],
      "source": [
        "#Classifier\n",
        "\n",
        "#Loss and Optimizer\n",
        "# Creare your loss here. Use Cross Entropy loss:\n",
        "loss = nn.CrossEntropyLoss()\n",
        "lr, wd = 0.0012, 0.0005\n",
        "\n",
        "# COptimizer Adam with weight decay wd and learning rate lr.\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the training model from lab 5 to show my model. I changed net(X) to net(stem(X)) to accomodate for my model."
      ],
      "metadata": {
        "id": "EOTGx4MsOrKB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlP5Bz1s6DBw"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_hat, y):  #y_hat is a matrix; 2nd dimension stores prediction scores for each class.\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1) # Predicted class is the index of max score         \n",
        "    cmp = (y_hat.type(y.dtype) == y)  # because`==` is sensitive to data types\n",
        "    return float(torch.sum(cmp)) # Taking the sum yields the number of correct predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh_mdCb96IHz"
      },
      "outputs": [],
      "source": [
        "class Accumulator:  \n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n # [0, 0, ..., 0]\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dT6UGyi6Kro"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(net, data_iter): \n",
        "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
        "    for _, (X, y) in enumerate(data_iter):\n",
        "        metric.add(accuracy(net(stem(X)), y), y.numel())\n",
        "    return metric[0] / metric[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlp6Lrkq6OKQ"
      },
      "outputs": [],
      "source": [
        "evaluate_accuracy(net, test_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAB19Iq56RXL"
      },
      "outputs": [],
      "source": [
        "def train_epoch_ch3(net, train_iter, loss, optimizer, batch_size=256, num_outputs=10):  \n",
        "    \"\"\"The training function for one epoch.\"\"\"\n",
        "    # Set the model to training mode\n",
        "    if isinstance(net, torch.nn.Module):\n",
        "        net.train()\n",
        "    # Sum of training loss, sum of training accuracy, no. of examples\n",
        "    metric = Accumulator(3)\n",
        "    for X, y in train_iter:\n",
        "        # Compute gradients and update parameters\n",
        "        y_hat = net(stem(X))\n",
        "        l = loss(y_hat, y)\n",
        "        optimizer.zero_grad()\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        metric.add(float(l) * len(y), accuracy(y_hat, y), y.size().numel())\n",
        "    # Return training loss and training accuracy\n",
        "    return metric[0] / metric[2], metric[1] / metric[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P2Hy7Ww6T-6"
      },
      "outputs": [],
      "source": [
        "class Animator:  \n",
        "    \"\"\"For plotting data in animation.\"\"\"\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "                 ylim=None, xscale='linear', yscale='linear',\n",
        "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
        "                 figsize=(3.5, 2.5)):\n",
        "        # Incrementally plot multiple lines\n",
        "        if legend is None:\n",
        "            legend = []\n",
        "        mu.use_svg_display()\n",
        "        self.fig, self.axes = mu.plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1:\n",
        "            self.axes = [self.axes, ]\n",
        "        # Use a lambda function to capture arguments\n",
        "        self.config_axes = lambda: mu.set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "\n",
        "    def add(self, x, y):\n",
        "        # Add multiple data points into the figure\n",
        "        if not hasattr(y, \"__len__\"):\n",
        "            y = [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"):\n",
        "            x = [x] * n\n",
        "        if not self.X:\n",
        "            self.X = [[] for _ in range(n)]\n",
        "        if not self.Y:\n",
        "            self.Y = [[] for _ in range(n)]\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRx_St0R6fHI"
      },
      "outputs": [],
      "source": [
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, optimizer): \n",
        "    \"\"\"Train a model.\"\"\"\n",
        "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.1, 0.9],\n",
        "                        legend=['train loss', 'train acc', 'test acc'])\n",
        "    for epoch in range(num_epochs):\n",
        "        train_metrics = train_epoch_ch3(net, train_iter, loss, optimizer)\n",
        "        test_acc = evaluate_accuracy(net, test_iter)\n",
        "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
        "    train_loss, train_acc = train_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2CVftai6hy4"
      },
      "outputs": [],
      "source": [
        "num_epochs = 25\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, optimizer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}